{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.PAC_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/MIU_ML/blob/main/notebooks/02.PAC_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQXhiZhJTcDQ"
      },
      "source": [
        "# PAC Learning\n",
        "\n",
        "PAC stands for 'Probably Approximately Correct'. PAC gives you the confidence and the correctness for the hypothesis.\n",
        "\n",
        "This short lecture is an excellent learning material for PAC Learning [Probably Approximately Correct (PAC)Learning ( KTU CS467 Machine Learning Module 2)](https://youtu.be/fTWm2S5tFCo)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4F22CuwUsv6"
      },
      "source": [
        "## Derivation of the PAC inequality\n",
        "\n",
        "The goal of PAC is to estimate the number of samples required for the given accuracy goal (1 - $ \\epsilon $) and confidence (1 - $ \\delta$).\n",
        "The PAC inequality is thus:\n",
        "\n",
        "$$ P \\{ C \\Delta h \\leq \\epsilon \\} \\geq 1 - \\delta $$\n",
        "\n",
        "- C: Class/Concept\n",
        "- h: hypothesis\n",
        "- $ C \\Delta h $: difference between C and h (Error)\n",
        "- $ \\epsilon $: error uppperbound\n",
        "  - $ (1 - \\epsilon) $: accuracy target\n",
        "- $ \\delta $: probability of failure\n",
        "  - $ (1 - \\delta) $: confidence\n",
        "\n",
        "In our example, assuming that we draw the tightest rectangle as the hypothesis (yellow rectangle) and the real class C is the outer rectangle (green rectangle), the error is the area between the two rectangles. Any data points falling in this area will be incorrectly classified by the hypothesis (false negative: the hypothesis says it is a negative case but is not).\n",
        "\n",
        "We want to make sure that The probability of a positive example falling in one of the error areas is at most $ \\epsilon / 4 $.\n",
        "\n",
        "- $ \\epsilon / 4 $: Since $ \\epsilon $ is the error upperbound, one strip of the error area needs to be at most $ \\epsilon / 4 $ (greyed area).\n",
        "- $ (1 - \\epsilon / 4) $: The probability that a randomly drawn sample to be not in one of the error strips.\n",
        "- $ (1 - \\epsilon / 4)^N $: The combined probability that N number of samples will miss one error strip since they are all independent.\n",
        "- $ 4(1 - \\epsilon / 4)^N $: The combined probability for all N samples to miss all 4 error strips.\n",
        "\n",
        "We would like $ 4(1 - \\epsilon / 4)^N $ to be at most $ \\delta $. Thus the inequality is:\n",
        "\n",
        "\n",
        "$$ 4(1 - \\epsilon / 4)^N \\leq \\delta $$\n",
        "\n",
        "Diving by 4 on both sides gives us:\n",
        "$$ (1 - \\epsilon / 4)^N \\leq \\delta / 4 $$\n",
        "\n",
        "What we need to know is N (number of required samples) so let's try to isolate N.\n",
        "\n",
        "To do that, let's use the inequality:\n",
        "\n",
        "$$ (1 - x) \\leq e^{-x} $$\n",
        "\n",
        "This can be quickly verified: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZyBwtm-YPdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36f7863c-217c-46a8-d4f3-818634548917"
      },
      "source": [
        "import math\n",
        "\n",
        "x = -4\n",
        "print(\"{} <= {}\".format(1 - x, math.exp(-x)))\n",
        "\n",
        "x = -1\n",
        "print(\"{} <= {}\".format(1 - x, math.exp(-x)))\n",
        "\n",
        "x = 0\n",
        "print(\"{} <= {}\".format(1 - x, math.exp(-x)))\n",
        "\n",
        "x = 4\n",
        "print(\"{} <= {}\".format(1 - x, math.exp(-x)))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 <= 54.598150033144236\n",
            "2 <= 2.718281828459045\n",
            "1 <= 1.0\n",
            "-3 <= 0.01831563888873418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg-ApYp4YF9R"
      },
      "source": [
        "Substituting x with $ \\epsilon / 4 $ the lefthand of the inequality is replaced with the righthand of this inequality:\n",
        "\n",
        "$$ (1 - \\epsilon / 4)^N \\leq (e^{-\\epsilon / 4})^N $$\n",
        "\n",
        "Thus,\n",
        "$$ e^{-N (\\epsilon / 4)} \\leq \\frac{\\delta}{4} $$\n",
        "\n",
        "Taking the log on both sides gives us:\n",
        "\n",
        "$$ \\ln e^{-N (\\epsilon / 4)} \\leq \\ln \\frac{\\delta}{4} $$\n",
        "\n",
        "Now we need to solve the inequality involving logarithms. Here is a [cheat sheet](https://study.com/academy/lesson/how-to-solve-logarithmic-exponential-inequalities.html) on how to do it.\n",
        "\n",
        "Using the method, the inequality becomes:\n",
        "\n",
        "$$ -N (\\epsilon / 4)\\ln e \\leq \\ln \\frac{\\delta}{4} $$\n",
        "\n",
        "Since $ \\ln e = 1 $, we can simply it as:\n",
        "\n",
        "$$ -N (\\epsilon / 4) \\leq \\ln \\frac{\\delta}{4} $$\n",
        "\n",
        "THen multiplying both sides with $ 4/\\epsilon $ and getting rid of the negative sign on the left switches the inequality sign to arrive at this formula:\n",
        "\n",
        "$$ N \\geq \\frac{4}{\\epsilon} \\ln \\frac{\\delta}{4} $$\n",
        "\n",
        "Finally, we have a handy formula to calculate the number of sample required to achieve the target confidence ($1 - \\delta$) and the accuracy ($1 - \\epsilon$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQQ3ncvPn0KB"
      },
      "source": [
        "## Plotting C & h"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8QqASPls8qu"
      },
      "source": [
        "import matplotlib.patches as patches\n",
        "\n",
        "COLORS = [(0, 255/255, 0), (255/255, 255/255, 0), (255/255, 0, 0)]\n",
        "\n",
        "def create_patch_rectangle(y, color, fill=False):\n",
        "  width = (y[2] - y[0])\n",
        "  height = (y[3] - y[1])\n",
        "  if fill:\n",
        "    return patches.Rectangle((y[0], y[1]),\n",
        "                            width, height,\n",
        "                            edgecolor=color,\n",
        "                            facecolor='grey', fill=fill, alpha=0.3)\n",
        "  else:\n",
        "    return patches.Rectangle((y[0], y[1]),\n",
        "                            width, height,\n",
        "                            edgecolor=color, fill=fill)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7EM_Ev1s9bS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d697469e-93da-4fe3-d9e0-7fe51b28c89b"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = np.array([\n",
        "      # negative\n",
        "      [1.,    1.2],\n",
        "      [1.2,   .7],\n",
        "      [2.,    .8],    \n",
        "      [3.,    .85],\n",
        "      [3.1,   .5],\n",
        "      [2.9,   2.],\n",
        "      [1.7,    .2],    \n",
        "      [2.,    2.8],\n",
        "\n",
        "      # positive\n",
        "      [1.5,   1.5],\n",
        "      [2,     1.2],\n",
        "      [2.5,   1.7],\n",
        "      [2.,    2.],\n",
        "      [1.5,   2.]\n",
        "    ])\n",
        "y = np.array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1])\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data(X, y):\n",
        "  positives = X[y == 1]\n",
        "  negatives = X[y == 0]\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.plot(positives[:, 0], positives[:, 1], marker='+', linestyle='', ms=12, label='+')\n",
        "  ax.plot(negatives[:, 0], negatives[:, 1], marker='_', linestyle='', ms=12, label='-')\n",
        "  return ax\n",
        "\n",
        "# plt.scatter(X[:, 0], X[:, 1])\n",
        "\n",
        "ax = plot_data(X, y)\n",
        "# x_line = np.linspace(0, 10, 100)\n",
        "# y_line = -2.1*x_line + 20\n",
        "PADDING = 0.01\n",
        "rect1 = create_patch_rectangle((1.2, 2.4, 2.8, .9), COLORS[0])\n",
        "rect2 = create_patch_rectangle((1.4, 2.1, 2.6, 1.1), COLORS[1])\n",
        "rect3 = create_patch_rectangle((1.2 + PADDING, 2.4 - PADDING*2,\n",
        "                                2.8 - PADDING, 2.1 + PADDING*2),\n",
        "                                COLORS[2], fill=True)\n",
        "ax.add_patch(rect1)\n",
        "ax.add_patch(rect2)\n",
        "ax.add_patch(rect3)\n",
        "\n",
        "ax.text(x=2.0,\n",
        "         y=2.2,\n",
        "         s=chr(949) + '/4',\n",
        "         fontdict=dict(color='red',size=15),\n",
        "         bbox=dict(facecolor='white',alpha=0))\n",
        "\n",
        "# ax.plot(x_line, y_line, 'g', label='y=wx+b')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(2.0, 2.2, 'ε/4')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-vsXO_vmtPx"
      },
      "source": [
        "## Example\n",
        "If we use a rectangle hypothesis model to learn a concept with 99% correctness ($\\epsilon = 0.01$) with a probability of 95% ($\\delta = 0.05$), what is the minimum number of training samples?\n",
        "\n",
        "Plugging the numbers in the above formula, give us:\n",
        "\n",
        "$$ \\frac{4}{\\epsilon}\\ln\\frac{4}{\\delta} = \\frac{4}{0.01}\\ln\\frac{4}{0.05} = 1752.8 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zguyso0to2g7"
      },
      "source": [
        "In other words, you need at least 1753 training samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwHgvPeznwip",
        "outputId": "a42879e8-4344-4cef-f7fe-34c605afc444"
      },
      "source": [
        "epsilon = 0.01\n",
        "delta = 0.05\n",
        "\n",
        "4/epsilon * math.log(4/delta)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1752.8106538695524"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2DKhyP0mhgp"
      },
      "source": [
        "# Appendix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGKzDofVmkYo"
      },
      "source": [
        "## How to print Greek alphabets in Python"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fmC8XhAQihQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ab8597b-ba76-4c2b-8b02-b136ddedb017"
      },
      "source": [
        "greek_letterz=[(chr(code), code) for code in range(945,970)]\n",
        "\n",
        "print(greek_letterz)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('α', 945), ('β', 946), ('γ', 947), ('δ', 948), ('ε', 949), ('ζ', 950), ('η', 951), ('θ', 952), ('ι', 953), ('κ', 954), ('λ', 955), ('μ', 956), ('ν', 957), ('ξ', 958), ('ο', 959), ('π', 960), ('ρ', 961), ('ς', 962), ('σ', 963), ('τ', 964), ('υ', 965), ('φ', 966), ('χ', 967), ('ψ', 968), ('ω', 969)]\n"
          ]
        }
      ]
    }
  ]
}