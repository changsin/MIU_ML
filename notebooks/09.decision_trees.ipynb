{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09.decision_trees",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsin/MIU_ML/blob/main/notebooks/09.decision_trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HclJutxS2bYj"
      },
      "source": [
        "# Decision Tree\n",
        "\n",
        "The following is an explanation of Decision Tree (section 8.4, pp. 200~) in Ertel's Artificial Intelligence. The data used is reproduced below. The last column _Skiing_ represents the target decision of either going or not going to skiing.\n",
        "\n",
        "\n",
        "| Day | Snow_Dist | Weekend | Sun | Skiing |\n",
        "| ----| --------|-----------|------| ------|\n",
        "| 1 | $ \\leq $100 | yes | yes | yes |\n",
        "| 2 | $ \\leq $100 | yes | yes | yes |\n",
        "| 3 | $ \\leq $100 | yes | no | yes |\n",
        "| 4 | $ \\leq $100 | no | yes | yes |\n",
        "| 5 | >100 | yes | yes | yes |\n",
        "| 6 | >100 | yes | yes | yes |\n",
        "| 7 | >100 | yes | yes | no |\n",
        "| 8 | >100 | yes | no | no |\n",
        "| 9 | >100 | no | yes | no |\n",
        "| 10 | >100 | no | yes | no |\n",
        "| 11 | >100 | no | no | no |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oFEJiGK0ZwY"
      },
      "source": [
        "## Entropy\n",
        "\n",
        "The entropy is calculated according to Shannon's formula:\n",
        "\n",
        "$ H(p) = H(p_1;...p_n) = -\\Sigma_{n=1}^{n}p_i log_2 p_i = H(D) $\n",
        "\n",
        "Applied to the skiing example in the text book, we calculate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNlVpQa2mVhN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hQBW-9ork94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7d60667-8bb6-4996-c5f5-2bdfd189a8e4"
      },
      "source": [
        "p1 = 5/11\n",
        "p2 = 6/11\n",
        "p3 = 7/11\n",
        "\n",
        "probs = np.array([p1, p2])\n",
        "\n",
        "def calculate_entropy(probs):\n",
        "  entropy = 0\n",
        "  for p in probs:\n",
        "    if p != 0:\n",
        "      entropy += p*np.log2(p)\n",
        "  \n",
        "  return -entropy\n",
        "\n",
        "\n",
        "\n",
        "H = -(p1*np.log2(p1)) - (p2*np.log2(p2))\n",
        "H\n",
        "\n",
        "calculate_entropy(probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9940302114769565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5ItFMaGdmjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132f037e-7442-45ac-fc1c-e94a0cd661b9"
      },
      "source": [
        "calculate_entropy(np.array([2/7, 5/7]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863120568566631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUMuUsBAj3HZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe62e1bf-a5e7-4f38-90dd-aff6336cea75"
      },
      "source": [
        "calculate_entropy(np.array([4/4, 0/4]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYI4IgstkfDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e11b88-c292-4259-fffb-130778fa7691"
      },
      "source": [
        "calculate_entropy(np.array([6/11, 5/11]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9940302114769565"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEJK8GTX2FgC"
      },
      "source": [
        "## Information Gain\n",
        "\n",
        "For dataset D, the information gained is thus:\n",
        "\n",
        "$$ I(D) = 1 - H(D) $$\n",
        "\n",
        "The information gain through attribute A is defined as:\n",
        "$$ G(D, A) = \\Sigma_{i=1}^{n}\\frac{|D_i|}{|D|}I(D_i) - I(D) $$\n",
        "\n",
        "or if we rewrite it in terms of entropy:\n",
        "\n",
        "$$ = H(D) - \\Sigma_{i=1}^{n}\\frac{|D_i|}{|D|}H(D_i) $$\n",
        "\n",
        "Applied to our skiing example, for the choice of snow distribution, we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9zs5opWrKGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eb12f8-df0f-4584-9931-1e28d3c1bdf9"
      },
      "source": [
        "D = 11\n",
        "D_snow_little = 4\n",
        "D_snow_big = 7\n",
        "H_D = calculate_entropy(np.array([6/11, 5/11]))\n",
        "H_snow_little = calculate_entropy(np.array([4/4, 0/4]))\n",
        "H_snow_big = calculate_entropy(np.array([2/7, 5/7]))\n",
        "H_snow_big"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.863120568566631"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NuMkVGr14g4"
      },
      "source": [
        "0.863 is the entropy we get when we branch the decision tree for snow distribution. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRc9s5NjlwhL"
      },
      "source": [
        "def calculate_information_gain(dataset_count, initial_entropy, subs):\n",
        "  \"\"\"\n",
        "    dataset_count: total number of entries in the dataset\n",
        "    initial_entropy: the initial entropy of the dataset\n",
        "    subs: a list of positive and negative counts for each sub-branch:\n",
        "      e.g., [[4, 0], [2, 5]] means that for snow_dist,\n",
        "       for the positive case, <= 100 give you 4 correct and 0 incorrect answers.\n",
        "       for the negative case, 2 incorrect and 5 correct answers.\n",
        "  \"\"\"\n",
        "  sub_entropy = 0\n",
        "\n",
        "  for sub in subs:\n",
        "    sub_counts = np.array(sub)\n",
        "    sub_total = np.sum(sub_counts)\n",
        "    sub_probs = np.array([ di/sub_total for di in sub_counts])\n",
        "\n",
        "    entropy = calculate_entropy(sub_probs)\n",
        "    print(\"subentropy\", entropy)\n",
        "\n",
        "    sub_entropy += (sub_total/dataset_count)*entropy\n",
        "\n",
        "  return initial_entropy - sub_entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SATgMWe71Tsj"
      },
      "source": [
        "# How to build a decision tree with information gain metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LipppCdD04YR"
      },
      "source": [
        "Using the information gain formula, we can now calculate and compare what is the best way to build a decision tree. Given there are three attributes, we calculate the information gain for each as follows.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqZzohnm1S7h"
      },
      "source": [
        "### A1: Snow distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2Oew6GM026M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f2d1a3f-f61f-42f9-b10a-8f846d09a86d"
      },
      "source": [
        "H_D = calculate_entropy(np.array([6/11, 5/11]))\n",
        "sub_snow = [[4, 0],\n",
        "            [2, 5]]\n",
        "calculate_information_gain(11, H_D, sub_snow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subentropy -0.0\n",
            "subentropy 0.863120568566631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44477166784364586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e546ow3h2cWo"
      },
      "source": [
        "### A2: Weekend"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZZalp3mpazt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f8715c-1ba0-409a-858a-558795bf565d"
      },
      "source": [
        "sub_weekend = [[5, 2],\n",
        "               [1, 3]]\n",
        "calculate_information_gain(11, H_D, sub_weekend)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subentropy 0.863120568566631\n",
            "subentropy 0.8112781244591328\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14976144076759756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBZNWVgw2kaU"
      },
      "source": [
        "### A3: Sun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7cryB1YreL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c3e4b52-ba3f-45f1-8050-54ebc8e6794d"
      },
      "source": [
        "sub_sun = [[5, 3],\n",
        "            [1, 2]]\n",
        "calculate_information_gain(11, H_D, sub_sun)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subentropy 0.9544340029249649\n",
            "subentropy 0.9182958340544896\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0494520727893939"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scJoerE52oLI"
      },
      "source": [
        "Based on the results, we know that snow distribution is the first branch question we should ask to get the most information gain."
      ]
    }
  ]
}
